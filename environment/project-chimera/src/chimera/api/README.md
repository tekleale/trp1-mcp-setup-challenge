# API Module

## Overview

This module provides the FastAPI REST API layer for Project Chimera's agent orchestration system. It exposes HTTP endpoints for submitting goals, executing tasks, and managing human-in-the-loop (HITL) reviews.

**Spec Reference:** specs/technical.md Section 7 (API Contracts)

---

## Module Purpose

### What is the API Module?

The API module serves as the **external interface** for Project Chimera, enabling:
- **Goal submission:** Users submit high-level objectives via REST API
- **Task execution:** Trigger Worker agent to execute individual tasks
- **Quality assessment:** Invoke Judge agent to evaluate task outputs
- **HITL management:** Human reviewers approve/reject Tier 2 tasks

### Why FastAPI?

**Spec Requirement:** specs/technical.md Section 7 mandates FastAPI for API layer.

**Benefits:**
- **Async support:** Native async/await for LangGraph integration
- **Pydantic validation:** Automatic request/response validation
- **OpenAPI docs:** Auto-generated API documentation
- **Type safety:** Full type hints for IDE support
- **Performance:** High throughput for agent orchestration

---

## Components

### 1. Planner Router (`planner.py`)

**Prefix:** `/planner`  
**Agent:** PlannerAgent  
**Purpose:** Goal submission and task plan retrieval

**Endpoints:**

#### `POST /planner/tasks` - Submit New Goal
- **Purpose:** Accept high-level goal and trigger planning
- **Request:** `SubmitGoalRequest` (goal, context, constraints)
- **Response:** `SubmitGoalResponse` (session_id, status, created_at)
- **Status Code:** 202 Accepted
- **Spec:** specs/technical.md Section 7.1

**Example:**
```bash
curl -X POST http://localhost:8000/planner/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "goal": "Research trending AI topics on Twitter",
    "context": {"platform": "twitter", "timeframe": "24h"},
    "constraints": ["no political content", "english only"]
  }'
```

#### `GET /planner/tasks/{session_id}` - Get Task Plan
- **Purpose:** Retrieve task plan generated by Planner
- **Response:** `GetTasksResponse` (session_id, tasks, reasoning, estimated_duration)
- **Status Code:** 200 OK
- **Spec:** specs/technical.md Section 7.2

---

### 2. Worker Router (`worker.py`)

**Prefix:** `/worker`  
**Agent:** WorkerAgent  
**Purpose:** Task execution and status monitoring

**Endpoints:**

#### `POST /worker/execute` - Execute Task
- **Purpose:** Execute individual task using Worker agent
- **Request:** `ExecuteTaskRequest` (task_id, task_type, mcp_tool, parameters, timeout)
- **Response:** `ExecuteTaskResponse` (task_id, status, output, execution_time, mcp_trace)
- **Status Code:** 200 OK
- **Spec:** specs/functional.md Section 2.2

**Example:**
```bash
curl -X POST http://localhost:8000/worker/execute \
  -H "Content-Type: application/json" \
  -d '{
    "task_id": "task_xyz789",
    "task_type": "mcp_call",
    "description": "Fetch trending topics",
    "mcp_tool": "twitter_trends",
    "parameters": {"location": "US", "limit": 10},
    "timeout": 30
  }'
```

#### `GET /worker/status/{task_id}` - Get Task Status
- **Purpose:** Monitor task execution progress
- **Response:** `GetTaskStatusResponse` (task_id, status, progress, started_at, completed_at)
- **Status Code:** 200 OK
- **Spec:** specs/technical.md Section 2.2

---

### 3. Judge Router (`judge.py`)

**Prefix:** `/judge`  
**Agent:** JudgeAgent  
**Purpose:** Quality assessment and HITL review management

**Endpoints:**

#### `POST /judge/assess` - Assess Content Quality
- **Purpose:** Evaluate task output and determine HITL routing
- **Request:** `AssessContentRequest` (task_id, content, guidelines)
- **Response:** `AssessContentResponse` (approved, confidence, requires_human_review, quality_metrics)
- **Status Code:** 200 OK
- **Spec:** specs/functional.md Section 2.3

**HITL Routing Logic (NON-NEGOTIABLE):**
- **confidence > 0.90:** Auto-approve (Tier 1)
- **0.70 ≤ confidence ≤ 0.90:** Human review required (Tier 2)
- **confidence < 0.70:** Auto-reject (Tier 3)

**Spec Reference:** specs/_meta.md Section 3.2 (HITL Thresholds)

#### `GET /judge/reviews` - List Pending Reviews
- **Purpose:** Retrieve all Tier 2 tasks awaiting human review
- **Response:** `GetReviewsResponse` (reviews, total)
- **Status Code:** 200 OK
- **Spec:** specs/technical.md Section 7.3

#### `POST /judge/reviews/{review_id}/approve` - Approve Review
- **Purpose:** Human reviewer approves Tier 2 task
- **Request:** `ReviewDecisionRequest` (reason)
- **Response:** `ReviewDecisionResponse` (review_id, decision, decided_at)
- **Status Code:** 200 OK
- **Spec:** specs/functional.md Section 3.3

#### `POST /judge/reviews/{review_id}/reject` - Reject Review
- **Purpose:** Human reviewer rejects Tier 2 task
- **Request:** `ReviewDecisionRequest` (reason)
- **Response:** `ReviewDecisionResponse` (review_id, decision, decided_at)
- **Status Code:** 200 OK
- **Spec:** specs/functional.md Section 3.3

---

## Agent Correspondence

| Router | Agent | Responsibility |
|--------|-------|----------------|
| `/planner` | PlannerAgent | Decompose goals into tasks |
| `/worker` | WorkerAgent | Execute tasks via MCP tools |
| `/judge` | JudgeAgent | Assess quality, route HITL |

**Workflow:**
1. User submits goal → `POST /planner/tasks` → PlannerAgent creates task queue
2. System executes tasks → `POST /worker/execute` → WorkerAgent calls MCP tools
3. System assesses output → `POST /judge/assess` → JudgeAgent calculates confidence
4. If Tier 2 → Human reviews → `POST /judge/reviews/{id}/approve` or `/reject`

---

## Implementation Status

**Current:** Skeleton with stub endpoints and comprehensive docstrings  
**Next Steps:**
1. Implement FastAPI app initialization (main.py)
2. Integrate routers with LangGraph state machine
3. Connect endpoints to agent classes (PlannerAgent, WorkerAgent, JudgeAgent)
4. Implement Redis state persistence
5. Add Tenx Sense logging for all API calls
6. Write integration tests with mock agents

---

## Governor Mode Compliance

✅ **FastAPI Stubs Only:** All endpoints raise HTTP 501 Not Implemented  
✅ **Comprehensive Docstrings:** Purpose, inputs, outputs, failure modes documented  
✅ **Pydantic Schemas:** Request/response models with validation rules  
✅ **No Real Agent Calls:** No integration with PlannerAgent, WorkerAgent, JudgeAgent  
✅ **Spec Alignment:** All contracts match specs/technical.md Section 7  
✅ **HITL Thresholds:** 0.90/0.70 hardcoded (NON-NEGOTIABLE)  
✅ **Single Commit:** All files committed together  

---

## Testing Requirements

**Unit Tests Required:**
- `tests/api/test_planner.py`
  - Test request validation (goal length, constraints)
  - Test response schema (session_id format, status values)
  - Test error handling (400, 422, 500)

- `tests/api/test_worker.py`
  - Test task execution request validation
  - Test timeout enforcement (5-300 seconds)
  - Test MCP trace structure

- `tests/api/test_judge.py`
  - Test HITL routing logic (0.90/0.70 thresholds)
  - Test quality metrics calculation
  - Test review approval/rejection flows

**Mock Strategy:**
```python
from fastapi.testclient import TestClient
from chimera.api import planner_router, worker_router, judge_router

app = FastAPI()
app.include_router(planner_router)

client = TestClient(app)

def test_submit_goal_validation():
    # Test goal too short
    response = client.post("/planner/tasks", json={"goal": "Hi"})
    assert response.status_code == 422
```

**Spec Reference:** specs/technical.md Section 9 (Testing Contracts)

---

## References

- specs/technical.md Section 7 (API Contracts)
- specs/functional.md Section 2 (Agent Behavioral Contracts)
- specs/_meta.md Section 3.2 (HITL Thresholds - NON-NEGOTIABLE)
- .cursor/rules Section 6 (API Development Rules)

